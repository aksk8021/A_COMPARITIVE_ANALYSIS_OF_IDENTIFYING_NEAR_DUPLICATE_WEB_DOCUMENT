I am Ankit Kumar Singh, and I have finalized a project on near-duplicate detection with the assistance of various research papers. This project was a collaborative effort completed with the help of my brother, Aditya Singh.

For reference, my brother's GitHub profile is available at: https://github.com/863aditya.

Testing was conducted on ideal datasets, where only the paragraph tags were parsed. These datasets were specifically created for testing purposes. If you wish to test the project on different data, minor adjustments will be necessary.

The purpose of this analysis and assessment is for research and future enhancements to the project.

During the project, all datasets were located in the same directory as the Python files. However, for uploading, I have separated them into different files for better organization.

To run this project on your machine, follow these summarized steps:

Download the repository and extract it into a new folder.
Ensure that all datasets are in their respective directories.
Create two text files named "res.txt" and "res1.txt" for stemmed and unstemmed analysis.
From the "Localhost" folder, execute the "app.py" Python script using PowerShell or Command Prompt. (HTML parsing is done on the localhost server.)
Next, run the required Python files from PowerShell or Command Prompt. If any input is required, enter it in the PowerShell window, such as "u100.xls" as used in our project.
Note: To run Python scripts from PowerShell, open the file's directory, press Shift, right-click the mouse, and then select "Open PowerShell window here." Type python FILENAME.py. If the script requires input, provide it in the PowerShell window on the next line.

If you notice any unconventional names used for Jupyter or Python files, these were employed solely for testing purposes and might be present in some places.

Credits for "NDD_3":
"A Near-Duplicate Detection Algorithm to Facilitate Document Clustering," published in November 2014. DOI: 10.5121/ijdkp.2014.4604. For more information, visit: https://www.researchgate.net/publication/276272813.

Credits for "NDD_1":
"A Novel and Efficient Approach For Near Duplicate Page Detection in Web Crawling," published in April 2009. DOI: 10.1109/IADCC.2009.4809238. For more information, visit: https://www.researchgate.net/publication/224398723.

All content used in this code is for educational purposes only. There is no intention to violate any copyrights, as all rights are owned by the respective authors.

Copyright Disclaimer under Section 107 of the Copyright Act 1976:
Fair use is permitted for purposes such as criticism, comment, news reporting, teaching, scholarship, education, and research. Fair use is a use permitted by copyright statute that might otherwise be infringing.
