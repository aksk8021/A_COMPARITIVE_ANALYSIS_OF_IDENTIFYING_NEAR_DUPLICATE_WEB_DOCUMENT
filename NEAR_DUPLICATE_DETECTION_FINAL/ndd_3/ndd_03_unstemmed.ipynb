{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "192fdbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "custom.xls\n"
     ]
    }
   ],
   "source": [
    "filename=input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "046e0bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8000/p1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "data=pd.read_excel(filename)\n",
    "# print(data[['linkk']]) \n",
    "df=pd.DataFrame(data)\n",
    "# dfs=df['linkk']\n",
    "print(df['links'][0])\n",
    "num_of_links=df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3795fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e82dcc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_string(l1):\n",
    "    s_0=\"\"\n",
    "    for i in range(len(l1)):\n",
    "        s_0+=l1[i]\n",
    "        s_0+=\" \"\n",
    "    print(s_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03d899a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()\n",
    "\n",
    "project_words=[]\n",
    "url_hash_list=[]\n",
    "def project_ndd(url):\n",
    "    r = requests.get(url)\t\t# r variable has all the HTML code\n",
    "    htmlContent = r.content\t# r returns response so if we want the code we write r.content\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    s1=\"\"\n",
    "    for i in soup.find_all(\"p\"):\n",
    "        a=(i.text)\n",
    "        s1+=(i.text)\n",
    "    l=list(s1.split())\n",
    "#     print(len(l))    \n",
    "    punc='''!()-[]{};:'\"\\,<>./?@#$%^&*_~”’“‘|'''\n",
    "    stop_word=[\"a\",\"the\",\"an\",\"is\"]\n",
    "    for ele in s1:\n",
    "        if ele in punc:\n",
    "            s1 = s1.replace(ele, \" \")\n",
    "    no_of_words=list(s1.split())\n",
    "    \n",
    "#     print(len(no_of_words)) \n",
    "    s2=\"\"\n",
    "    for i in no_of_words:\n",
    "        s2+=i\n",
    "        s2+=\" \"\n",
    "#     print(s2)\n",
    "    stop_words = stopwords.words('english')\n",
    "    l=list(s2.split())\n",
    "    for x in range(len(l)):\n",
    "        if l[x] in stop_words:\n",
    "            l[x]=\" \"\n",
    "#         l[x]=ps.stem(l[x])\n",
    "    s_inf=\"\"\n",
    "    for x in l:\n",
    "        s_inf+=(x)\n",
    "        s_inf+=\" \"\n",
    "#     print(s_inf)         \n",
    "    list_of_words=list(s_inf.split())\n",
    "    list_stemmed=[]\n",
    "    list_unstemmed=[]\n",
    "    for i in list_of_words:\n",
    "        list_stemmed.append(ps.stem(i))\n",
    "#     print_string(list_stemmed)\n",
    "    list_of_hash=[]\n",
    "    for i in list_stemmed:\n",
    "        HASHVALUE=hash(i)\n",
    "        list_of_hash.append(HASHVALUE)\n",
    "    # print(len(list_of_hash)) \n",
    "    url_hash_list.append(list((list_of_hash)))\n",
    "    project_words.append(len(list_of_hash))\n",
    "#     for i in list_of_hash:\n",
    "#         print(i,end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8f25909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#brute force method\n",
    "# s2=\"-1\"\n",
    "# while True:\n",
    "#     url=input()\n",
    "#     if url==\"-1\":\n",
    "#         break\n",
    "#     project_ndd(url)\n",
    "# print(project_words)\n",
    "# print(url_hash_list)\n",
    "\n",
    "#using pandas data frame\n",
    "for i in range(num_of_links):\n",
    "    url=df['links'][i]\n",
    "    project_ndd(url)\n",
    "# print(project_words)\n",
    "# print(url_hash_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12aec54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_name=[]\n",
    "for i in range(num_of_links):\n",
    "    a1=\"w{}\".format(i+1)\n",
    "    w_name.append(a1)\n",
    "# print(w_name)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bcf580b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_words=0\n",
    "for i in range(len(project_words)):\n",
    "    total_words+=project_words[i]\n",
    "count_of_unique=0\n",
    "count_of_ndd=0\n",
    "count_of_sus=0\n",
    "def similarity_percentage(hash_list,count_of_unique,count_of_ndd,count_of_sus):\n",
    "    final_score=[]\n",
    "    sim_per=[]\n",
    "    for i in range(len(url_hash_list)):\n",
    "        ll1=[]\n",
    "        for j in range(i+1,len(url_hash_list)):\n",
    "            ll=[]\n",
    "            if i==j:\n",
    "                continue\n",
    "            se=0\n",
    "            ele=0\n",
    "            for k in (url_hash_list[i]):\n",
    "                for l in (url_hash_list[j]):\n",
    "                    if l==k:\n",
    "                        ele=1\n",
    "                        break\n",
    "                se+=ele\n",
    "                ele=0\n",
    "            fi_p=se/(len(url_hash_list[i])+len(url_hash_list[j]))\n",
    "#             print(se,end=' ')\n",
    "#             print(len(url_hash_list[i]),end=\" \")\n",
    "#             print(len(url_hash_list[j]))\n",
    "            fi_p*=200\n",
    "            ll.append(fi_p)\n",
    "            ll.append(w_name[j])\n",
    "            ll.append(w_name[i])\n",
    "            if fi_p<60:\n",
    "                ll.append(\"unique\")\n",
    "                count_of_unique+=1\n",
    "            elif fi_p>60 and fi_p<80:\n",
    "                ll.append(\"suspicious\")\n",
    "                count_of_sus+=1\n",
    "            elif fi_p>=80:\n",
    "                ll.append(\"ndd\")\n",
    "                count_of_ndd+=1\n",
    "            ll1.append(ll)   \n",
    "        final_score.append(ll1)\n",
    "    print(\"the number of unique pairs is: \",count_of_unique)\n",
    "    print(\"the number of ndd pairs is: \",count_of_ndd)\n",
    "    print(\"the number of suspicious pairs is: \",count_of_sus)\n",
    "    with open(\"res1.txt\",\"a\") as f:\n",
    "        s1=f\"\"\"{count_of_unique} \"\"\"\n",
    "        s2=f\"\"\"{count_of_ndd} \"\"\"\n",
    "        s21=f\"\"\"{count_of_sus} \"\"\"\n",
    "        s3=f\"\"\"{filename} \"\"\"\n",
    "        f.write(\"stemmed \")\n",
    "        f.write(s3)\n",
    "        f.write(s1)\n",
    "        f.write(s2)\n",
    "        f.write(s21)\n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fcb50f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of unique pairs is:  0\n",
      "the number of ndd pairs is:  45\n",
      "the number of suspicious pairs is:  0\n"
     ]
    }
   ],
   "source": [
    "fi_s=similarity_percentage(url_hash_list,count_of_unique,count_of_ndd,count_of_sus)\n",
    "# print(set(fi_s)) \n",
    "l=[]\n",
    "# for i in range(len(fi_s)):\n",
    "#     print(fi_s[i])\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a8d6311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(project_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "008c5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlwt\n",
    "from xlwt import Workbook\n",
    "wb = Workbook()\n",
    "a=1\n",
    "b=1\n",
    "s=0\n",
    "s1 = wb.add_sheet('s1',cell_overwrite_ok=True)\n",
    "# for i in range(len(url_hash_list)):\n",
    "# #     for j in range(len(url_hash_list[i])):\n",
    "# #         sheet1.write(j,a,url_hash_list[i][j])\n",
    "    \n",
    "#     sheet1.write(s,0,b)\n",
    "#     sheet1.write(s,2,project_words[i])\n",
    "#     s+=1\n",
    "#     b+=1\n",
    "s1.write(1,0,\"DOCUMENT_CONSIDERED\")\n",
    "s1.write(1,1,\"DOCUMENT_COMPARED_AGAINST\")\n",
    "s1.write(1,2,\"SIMILARITY_PERCENTAGE\")\n",
    "s1.write(1,3,\"RESULT\")\n",
    "row=2\n",
    "for i in range(len(fi_s)):\n",
    "    for j in range(len(fi_s[i])):\n",
    "        s1.write(row,0,fi_s[i][j][2])\n",
    "        s1.write(row,1,fi_s[i][j][1])\n",
    "        s1.write(row,2,fi_s[i][j][0])\n",
    "        s1.write(row,3,fi_s[i][j][3])\n",
    "        row+=1\n",
    "wb.save(\"result\"+filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6026b2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3.8147077560424805 seconds ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41c233bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"res1.txt\",\"a\") as f:\n",
    "#     s1=f\"\"\"{count_of_unique} \"\"\"\n",
    "#     s2=f\"\"\"{count_of_ndd} \"\"\"\n",
    "#     s3=f\"\"\"{filename} \"\"\"\n",
    "#     f.write(\"unstemmed \")\n",
    "#     f.write(s3)\n",
    "#     f.write(s1)\n",
    "#     f.write(s2)\n",
    "    f.write(\"%s\\n\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f23c89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b934282",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76059632",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f544b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245fa263",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
